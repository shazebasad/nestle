{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "966fe423-7ef2-4fe8-b59f-6fe46c9a1e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting load_data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile load_data.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class DataProcessor:\n",
    "    def __init__(self, file_name):\n",
    "        \"\"\"\n",
    "        Initializes the DataProcessor with the file name and loads the data.\n",
    "\n",
    "        Parameters:\n",
    "        file_name (str): The name of the file to load.\n",
    "        \"\"\"\n",
    "        self.file_name = file_name\n",
    "        self.df = self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Loads data from a file into a DataFrame. Supports Excel and CSV files.\n",
    "\n",
    "        Returns:\n",
    "        DataFrame: The loaded data.\n",
    "        \"\"\"\n",
    "        if \".xlsx\" in self.file_name:\n",
    "            df = pd.read_excel(self.file_name)\n",
    "            return df\n",
    "        else:\n",
    "            df = pd.read_csv(self.file_name)\n",
    "            return df\n",
    "\n",
    "    def clean_data(self):\n",
    "        \"\"\"\n",
    "        Cleans the DataFrame by removing columns with names that start with 'Unnamed'.\n",
    "\n",
    "        Returns:\n",
    "        DataFrame: The cleaned DataFrame.\n",
    "        \"\"\"\n",
    "        self.df = self.df.filter(regex='^(?!Unnamed)')\n",
    "\n",
    "    def handle_missing_data(self, subset_column=\"\"):\n",
    "        \"\"\"\n",
    "        Handles missing data by dropping rows with missing values.\n",
    "\n",
    "        Parameters:\n",
    "        subset_column (str): The column to consider for missing values. If empty, considers all columns.\n",
    "\n",
    "        Returns:\n",
    "        DataFrame: The DataFrame with missing values handled.\n",
    "        \"\"\"\n",
    "        if subset_column == \"\":\n",
    "            self.df.dropna(inplace=True)\n",
    "        else:\n",
    "            self.df.dropna(subset=[subset_column], inplace=True)\n",
    "\n",
    "    def handle_duplicates(self, subset_column=\"\"):\n",
    "        \"\"\"\n",
    "        Handles duplicate values in the DataFrame.\n",
    "    \n",
    "        Parameters:\n",
    "        subset_column (str): The column to check for duplicates. If empty, considers all columns.\n",
    "    \n",
    "        Returns:\n",
    "        DataFrame: The DataFrame with duplicates handled.\n",
    "        \"\"\"\n",
    "        if subset_column == \"\":\n",
    "            self.df = self.df[~self.df.duplicated()]\n",
    "        else:\n",
    "            # Identify duplicates while keeping the first occurrence\n",
    "            duplicates = self.df[self.df.duplicated(subset=[subset_column], keep='first')]\n",
    "            \n",
    "            # Generate new 9-digit numbers for all duplicates\n",
    "            new_values = {val: random.randint(100000000, 999999999) for val in duplicates[subset_column].unique()}\n",
    "            \n",
    "            # Replace duplicates with new 9-digit numbers, excluding the first occurrence\n",
    "            for index, row in duplicates.iterrows():\n",
    "                self.df.at[index, subset_column] = new_values[row[subset_column]]\n",
    "            \n",
    "\n",
    "    def add_labeled_data(self, label_data, merge_column):\n",
    "        \"\"\"\n",
    "        Adds labels to the DataFrame by merging with another DataFrame.\n",
    "\n",
    "        Parameters:\n",
    "        label_data (DataFrame): The DataFrame containing the labels.\n",
    "        merge_column (str): The column name to use for merging.\n",
    "\n",
    "        Returns:\n",
    "        DataFrame: The merged DataFrame with labels added.\n",
    "        \"\"\"\n",
    "        label_df = pd.DataFrame(label_data)\n",
    "        self.df = pd.merge(self.df, label_df, how='left', left_on=merge_column, right_on=merge_column)\n",
    "        \n",
    "\n",
    "    def add_multiple_labels(self, label_data_dict):\n",
    "        \"\"\"\n",
    "        Adds multiple labels to the DataFrame by merging with several label DataFrames.\n",
    "\n",
    "        Parameters:\n",
    "        label_data_dict (dict): A dictionary where keys are column names and values are label DataFrames.\n",
    "\n",
    "        Returns:\n",
    "        DataFrame: The DataFrame with all labels added.\n",
    "        \"\"\"\n",
    "        for merge_column, label_data in label_data_dict.items():\n",
    "            self.add_labeled_data(label_data, merge_column)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa7984b-a149-4b6c-9258-1f85cd078f74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2024.02-py310",
   "language": "python",
   "name": "conda-env-anaconda-2024.02-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
